package mnb;

import java.io.File;
import java.io.FileNotFoundException;
import java.io.FilenameFilter;
import java.util.Map;
import java.util.Random;
import java.util.Scanner;
import java.util.Set;
import java.util.TreeMap;
import java.util.TreeSet;
import java.util.regex.Pattern;

import util.PorterStemmer;
import util.StopWords;

public class DC {

	// utilities:
	private StopWords stopword;
	private PorterStemmer stemmer;
	
	private int upperBoundTraining;
	private int upperBoundTest;
	
	// Map<Class, PartitionedDC>
	private Map<String, PartitionedDC> partitionedDCs;

	// holds on dinstinct instances of terms in the corpus
	private Set<String> vocab;
	// holds on dinstinct instances of terms in the DC_Training
	private Set<String> vocabDC_Training;

	private final String rootDir = "root" + File.separator;

	public DC(int _upperBoundTraining, int _upperBoundTest){
		this.stopword = new StopWords();
		this.stemmer = new PorterStemmer();
		this.partitionedDCs = new TreeMap<String, PartitionedDC>();
		this.vocab = new TreeSet<String>();
		this.vocabDC_Training = new TreeSet<String>();
		
		this.upperBoundTraining = _upperBoundTraining;
		this.upperBoundTest = _upperBoundTest;
	}

	/**
	* returns set of classes in the corpus
	*/
	public Set<String> getClasses(){
		return this.partitionedDCs.keySet();
	}

	/**
	* returns set of vocab in the corpus
	*/
	public Set<String> getVocab(){
		return this.vocab;
	}
	
	/**
	* returns set of vocab in the corpus
	*/
	public Set<String> getDC_TrainingVocab(){
		return this.vocabDC_Training;
	}

	/**
	* parses through all files for each folder
	* 1) extract folder name as class name for each folder
	* 2) extract document name as document Id for each document in the folder
	* 3) strip all emails in document
	* 4) split document with "\n\n"
	* 5) strip out the header of the document
	* 6) pass document file to be parsed
	 * @throws FileNotFoundException 
	*/
	@SuppressWarnings("resource")
	public void init(String dir) throws FileNotFoundException{
		
		// open document root directory
		File file = new File(rootDir + dir);
		
		// get all class names by directory names
		String[] classNames = file.list(new FilenameFilter(){
			@Override
			public boolean accept(File current, String name){
				return new File(current, name).isDirectory();
			}
		});

		// for each class in classes
		for(String className : classNames){
			// add class to collection
			this.addClass(className);
			
			// get all documents within a given class
			File[] documents = new File(rootDir + dir + File.separator + className).listFiles();
			
			// for each document in the class
			for(File document : documents){
				// get document name as document id
				String docId = document.getName();
				
				// store docId in collection, if result is 0, then doc was placed in training set, otherwise 1 for test set
				int DCSetResult = this.addDocument(docId, className);

				// split the document for any double new line
				Scanner docReader = new Scanner(document);
				docReader = docReader.useDelimiter("\n\n");
				
				// strip header and build body
				docReader.next();
				
				// for each part of the document divided by a double new line
				// CHECK IF DOCUMENT HAS A BODY, IF NOT, DO NOT ADD IT
				while(docReader.hasNext()){
					this.parseDoc(docReader.next(), className, docId, DCSetResult);
				}

				docReader.close();
			}
		}
	}

	/**
	* parses through document
	* 1) loop through each line of the document
	* 2) loop through each term of the line of the document
	* 3) take out punctation in term
	* 4) check if term is stop word, if it is, ignore the word
	* 5) stem the term
	* 6) add the Term to the partitioned documents
	*/
	private void parseDoc(String docPortion, String className, String docId, int DCSetResult){
		
		// domain regex patter
		String domainPattern = "[a-z0-9\\-\\.]+\\.(com|org|net|mil|edu|(co\\.[a-z].))";
		Pattern pFind = Pattern.compile(domainPattern);
		
		// scan the document portion
		Scanner docReader = new Scanner(docPortion);
		
		String line;
		
		// for each line in the document portion
		while(docReader.hasNextLine()){
			line = docReader.nextLine();
			
			// if line is blank, skip it
			if(line.equals("")){
				continue;
			}
			Scanner lineReader = new Scanner(line);
			
			String term;
			while(lineReader.hasNext()){
				
				term = lineReader.next();
				// if term matches the regex, skip it
				if(pFind.matcher(term).find()){
					continue;
				}
				
				// lower case term
				term = term.toLowerCase();
				// strip punctuation
				term = term.replaceAll("[^A-Za-z0-9]", "");
				
				// check if term is stopword
				if(this.stopword.contains(term)){
					continue;
				}
				
				// stem the term
				String stemmedTerm = this.stemmer.stem(term);
				if(!stemmedTerm.equals("Invalid term") 
						&& !stemmedTerm.equals("No term entered")){
					this.addTerm(className, docId, stemmedTerm, DCSetResult);
				}
			}
			lineReader.close();
		}
		docReader.close();
	}

	/**
	* adds a term to the DC_Training and DC_Test set with a specified document id
	*/
	private void addTerm(String className, String docId, String term, int DCSetResult){
		PartitionedDC partitionedDC = this.partitionedDCs.get(className);
		partitionedDC.addTerm(docId, term);
		this.partitionedDCs.put(className, partitionedDC);

		// include term in corpus terms
		this.vocab.add(term);
		
		// if the document containing the term is in the Training set, store it in the vocab of the DC_Training
		if(DCSetResult == 0){
			this.vocabDC_Training.add(term);
		}
	}

	/**
	* adds a document to the DC_Training and DC_Test set with specified class name
	*/
	private int addDocument(String docId, String className){
		PartitionedDC partitionedDC = this.partitionedDCs.get(className);
		
		// returns 0 if doc was placed in training set, otherwise 1 for test set
		int result = partitionedDC.addDocument(docId);
		
		this.partitionedDCs.put(className, partitionedDC);
		return result;
	}

	/**
	* add class to the DC
	*/
	private void addClass(String className){
		this.partitionedDCs.put(className, new PartitionedDC());
	}

	/*************************************************************************
		 					INFORMATION GAIN METRICS METHODS 
	**************************************************************************/
	/**
	* number of documents in DC_training in which w is absent that are labeled as c
	*/
	public double getNumberOfDocsInDC_TrainingWithout_W_Labeled_C(String className, String term){
		return this.partitionedDCs.get(className).getNumberOfDocsInDC_TrainingClassWithout_W(term);
	}

	/**
	* number of documents in DC_training in which w occurs that are labeled as c
	*/
	public double getNumberOfDocsInDC_TrainingWith_W_Labeled_C(String className, String term){
		return this.partitionedDCs.get(className).getNumberOfDocsInDC_TrainingClassWith_W(term);
	}

	/**
	* number of documents in DC_training labeled as c
	*/
	public int getNumberOfDocumentsInDC_TrainingLabeled_C(String className){
		return this.partitionedDCs.get(className).getNumberOfDocsInDC_TrainingClass();
	}

	/**
	* number of documents in DC_training in which w is absent
	* Total Number of documents in DC_training in which w is absent
	*/
	public int getNumberOfDocumentsInDC_TrainingWithout_W(String term){
		int count = 0;
		for(String key : this.partitionedDCs.keySet()){
			count += this.partitionedDCs.get(key).getNumberOfDocsInDC_TrainingClassWithout_W(term);
		}
		return count;
	}

	/**
	* number of documents in DC_training in which w occurs
	* Total number of documents in DC_training in which w occurs
	*/
	public double getNumberOfDocumentsInDC_TrainingWith_W(String term){
		double count = 0.0;
		for(String key : this.partitionedDCs.keySet()){
			count += this.partitionedDCs.get(key).getNumberOfDocsInDC_TrainingClassWith_W(term);
		}
		return count;
	}

	/**
	* Total Number of documents in DC_training
	*/
	public int getTotalNumberOfDocumentsInDC_Training(){
		int count = 0;
		for(String key : this.partitionedDCs.keySet()){
			count += this.partitionedDCs.get(key).getNumberOfDocsInDC_TrainingClass();
		}
		return count;
	}
	
	public Map<String, Map<String, Integer>> getDC_Training_Set(String className){
		if(this.partitionedDCs.containsKey(className)){
			return this.partitionedDCs.get(className).getDC_Training_Set();
		}
		return new TreeMap<String, Map<String, Integer>>();
	}
	
	public Map<String, Map<String, Integer>> getDC_Test_Set(String className){
		if(this.partitionedDCs.containsKey(className)){
			return this.partitionedDCs.get(className).getDC_Test_Set();
		}
		return new TreeMap<String, Map<String, Integer>>();
	}

	/*******************************************************************
	 * 					WORD PROBABILITY METRICS
	 *******************************************************************/
	
	/*******************************************************************
							WRAPPED CLASS
	 *******************************************************************/
	/**
	* CLASS PARTITIONED DC
	* This class includes the DC_Training Set and DC_TestSet, which are divided 80% and 20%
	*/
	private class PartitionedDC{

		//Map<DocId, Map<Term, Count>>
		private Map<String, Map<String, Integer>> DC_TrainingSet; 
		//Map<DocId, Map<Term, Count>>
		private Map<String, Map<String, Integer>> DC_TestSet; 

		//Map<Term, Set<DocId>> keeps track of how many documents include the term W.
		private Map<String, Set<String>> keyTermsDocCountTrainingSet;

		public PartitionedDC(){
			this.DC_TrainingSet = new TreeMap<String, Map<String, Integer>>();
			this.DC_TestSet = new TreeMap<String, Map<String, Integer>>();
			this.keyTermsDocCountTrainingSet = new TreeMap<String, Set<String>>();
		}

		/**
		* Check to see if the document id is included in the test set or training set
		* if in test set, include the term in the DC_TestSet, else include in the DC_TrainingSet
		*/
		public void addTerm(String docId, String term){
			if(this.DC_TrainingSet.containsKey(docId)){
				this.addTermToTrainingSet(docId, term);
			}
			else if(this.DC_TestSet.containsKey(docId)){
				this.addTermToTestSet(docId, term);
			}
		}

		/**
		* Add a term to the training set by document id
		* also include the document id in the key term set, which is used to keep track of how many documents contain the word w
		*/
		private void addTermToTrainingSet(String docId, String term){
			Map<String, Integer> keyTerms = this.DC_TrainingSet.get(docId);

			if(!keyTerms.containsKey(term)){
				keyTerms.put(term, 0);
			}

			// increment count
			int count = keyTerms.get(term);
			count++;
			keyTerms.put(term, count);

			// put set back in DC training set
			this.DC_TrainingSet.put(docId, keyTerms);

			// update DC_TrainingSet KeyTerm to Document count
			this.updateKeyTermsDocCount(docId, term);
		}

		/**
		* updates the the document count that contains the term w
		*/
		private void updateKeyTermsDocCount(String docId, String term){
			
			if(!this.keyTermsDocCountTrainingSet.containsKey(term)){
				this.keyTermsDocCountTrainingSet.put(term, new TreeSet<String>());
			}

			Set<String> docSet = this.keyTermsDocCountTrainingSet.get(term);
			docSet.add(docId);
			this.keyTermsDocCountTrainingSet.put(term, docSet);
		}

		/**
		* Add a term to the test set by document id
		*/
		private void addTermToTestSet(String docId, String term){
			Map<String, Integer> keyTerms = this.DC_TestSet.get(docId);

			if(!keyTerms.containsKey(term)){
				keyTerms.put(term, 0);
			}

			// increment count
			int count = keyTerms.get(term);
			count++;
			keyTerms.put(term, count);

			// put set back in DC training set
			this.DC_TestSet.put(docId, keyTerms);
		}

		/**
		* First choose a random number between 1 and 10, if the number is less than 9, include the document in the training set
		* otherwise include it in the test set.
		*/
		public int addDocument(String docId){
			// TODO: probably should make it 50/50 randomization
			if(randInt(1, 10) < 9){
				return this.addDocToTrainingSet(docId);
			}
			else{
				return this.addDocToTestSet(docId);
			}
		}

		/**
		* Checks to see if the number of documents in training set is greater than or equal to 800, if so add the document to the Test Set, 
		* otherwise, add it to the training set.
		*/
		private int addDocToTrainingSet(String docId){
			if(this.DC_TrainingSet.size() >= upperBoundTraining){
				this.DC_TestSet.put(docId, new TreeMap<String, Integer>());
				return 1;
			}
			else{
				this.DC_TrainingSet.put(docId, new TreeMap<String, Integer>());
				return 0;
			}
		}

		/**
		* Checks to see if the number of documents in test set is greater than or equal to 200, if so add the document to the Training Set, 
		* otherwise, add it to the test set.
		*/
		private int addDocToTestSet(String docId){
			if(this.DC_TestSet.size() >= upperBoundTest){
				this.DC_TrainingSet.put(docId, new TreeMap<String, Integer>());
				return 0;
			}
			else{
				this.DC_TestSet.put(docId, new TreeMap<String, Integer>());
				return 1;
			}
		}
		
		public Map<String, Map<String, Integer>> getDC_Training_Set(){
			return this.DC_TrainingSet;
		}

		public Map<String, Map<String, Integer>> getDC_Test_Set(){
			return this.DC_TestSet;
		}
		
		/**
		 * Returns a psuedo-random number between min and max, inclusive.
		 * The difference between min and max can be at most
		 * <code>Integer.MAX_VALUE - 1</code>.
		 *
		 * @param min Minimim value
		 * @param max Maximim value.  Must be greater than min.
		 * @return Integer between min and max, inclusive.
		 * @see java.util.Random#nextInt(int)
		 */
		public int randInt(int min, int max) {

		    // Usually this can be a field rather than a method variable
		    Random rand = new Random();

		    // nextInt is normally exclusive of the top value,
		    // so add 1 to make it inclusive
		    int randomNum = rand.nextInt((max - min) + 1) + min;

		    return randomNum;
		}

		// METRIC METHODS //

		/**
		* get the total count of documents in the training set for this particular set
		*/
		public int getNumberOfDocsInDC_TrainingClass(){
			return this.DC_TrainingSet.size();
		}

		/**
		* get the total count of documents in the training set for this particular set that contain the term w
		*/
		public double getNumberOfDocsInDC_TrainingClassWith_W(String term){
			double value = 0.0;
			if(this.keyTermsDocCountTrainingSet.containsKey(term)){
				value = (double)this.keyTermsDocCountTrainingSet.get(term).size();
			}
			//Laplacian smoothed estimate?????? /* WILL REVERT BACK TO HERE */
			return (value + 1.0) / (this.DC_TrainingSet.size() + 1);
			//return value;
		}

		/**
		* get the total count of documents in the training set for this particular set that absents the term w
		*/
		public double getNumberOfDocsInDC_TrainingClassWithout_W(String term){
			double value = 0.0;
			if(this.keyTermsDocCountTrainingSet.containsKey(term)){
				value = this.keyTermsDocCountTrainingSet.get(term).size();
			}
			return this.DC_TrainingSet.size() - value ;
		}
	}
}
